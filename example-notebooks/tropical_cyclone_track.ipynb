{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d0abe97",
   "metadata": {},
   "source": [
    "## BUFR tropical cyclone example\n",
    "\n",
    "This notebook provides an example on how to decode BUFR data using the ecCodes library. In this example, we will read tropical cyclone track data from the ECMWF ensemble forecasting system and do a basic analysis to calculate the tropical cyclone strike probability and display the result on a map.\n",
    "\n",
    "As part of the WIS2 Training you will be asked to download some data from the WIS2-broker hosted at `wis2training-broker.wis2dev.io` and use it in this notebook.\n",
    "If you want to run this notebook on you local machine, you can use the sample-data included in this notebook instead.\n",
    "\n",
    "The following references were used to create this notebook:\n",
    "- sample data from https://essential.ecmwf.int/\n",
    "- python code to load BUFR data based on ecCodes example, see https://confluence.ecmwf.int/display/ECC/bufr_read_tropical_cyclone\n",
    "\n",
    "Execute each block of code by selecting it and pressing `Shift+Enter` or clicking the `Run` button in the toolbar above.\n",
    "\n",
    "The first block will attempt to find the latest tropical cyclone file in the `/downloads` directory. If you are running this notebook outside of the WIS2 Training, use the sample data provided by uncommenting the line `#infile = '/root/sample-data/...'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd7de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def find_latest_file_with_path(root_dir, sub_path, extension):\n",
    "    search_pattern = os.path.join(root_dir, '**', sub_path, f'*.{extension}')\n",
    "    matching_files = glob.glob(search_pattern, recursive=True)\n",
    "    if not matching_files:\n",
    "        return None\n",
    "    return max(matching_files, key=os.path.getmtime)\n",
    "\n",
    "root_dir = '/downloads'\n",
    "sub_path = 'forecast/medium-range/probabilistic/trajectory'\n",
    "extension = 'bin'\n",
    "\n",
    "infile = find_latest_file_with_path(root_dir, sub_path, extension)\n",
    "\n",
    "if infile:\n",
    "    print(f\"The latest .bin file with the path '{sub_path}' is: {infile}\")\n",
    "\n",
    "# or use this file to run the notebook without having downloaded the data\n",
    "#infile = \"/root/sample-data/A_JSXX03ECEP010600_C_ECMP_20241001060000_tropical_cyclone_track_KIRK_-37p5degW_14p7degN_bufr4.bin\"\n",
    "\n",
    "if not os.path.exists(str(infile)):\n",
    "    raise FileNotFoundError(f\"{str(infile)} not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d581805-c817-4805-89f7-0e4b7b47e867",
   "metadata": {},
   "source": [
    "### Importing the required modules and defining helper functions\n",
    "\n",
    "The following block imports the required modules and defines the helper functions to load the tropical cyclone track data and calculate the strike probabilities.\n",
    "\n",
    "The following modules are imported:\n",
    "- eccodes: python interface to ecCodes, to read BUFR data\n",
    "- numpy: numerical python library, to handle numerical data\n",
    "- matplotlib: plotting library, to create the map\n",
    "- cartopy: cartographic library, to add map features\n",
    "\n",
    "\n",
    "The following helper functions are defined:\n",
    "- demo_load_cyclone_track: function to load ensemble of cyclone tracks from BUFR file.\n",
    "- create_grid: function to create the analysis grid on which to calculate the strike probabilities.\n",
    "- calculate_track_probabilities: function to calculate the strike probability based on the ensmeble of tracks and analsysis grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e59063ed-5851-4122-8db3-925ea3b86e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.feature import LAND, OCEAN, COASTLINE\n",
    "from datetime import datetime as dt, timedelta\n",
    "from eccodes import codes_bufr_new_from_file, codes_set, codes_get, codes_get_array, codes_get_double, codes_get_long\n",
    "from eccodes import CODES_MISSING_DOUBLE\n",
    "from functools import partial\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import colormaps\n",
    "import numpy as np\n",
    "import pyproj\n",
    "from shapely.geometry import shape, Point, MultiPoint\n",
    "from shapely.ops import transform\n",
    "\n",
    "def demo_load_cyclone_track(filename):\n",
    "    \"\"\"\n",
    "    Returns cyclone track information loaded from BUFR file.\n",
    "\n",
    "    NOTE: THIS CODE IS PROVIDED FOR DEMONSTRATION PURPOSES AND SHOULD NOT BE USED OPERATIONALLY.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    infile : string\n",
    "        Path to the BUFR file containing the data to read.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    stormIdentifier: string\n",
    "        Identifier allocated to the storm.\n",
    "    t0 : datetime\n",
    "        Date and time of the forecast.\n",
    "    deterministic : dictionary\n",
    "        geojson type object containing the track as a MultiPoint feature, including sea level pressure (slp)\n",
    "        and time step (datetime) as properties.\n",
    "    objs : list\n",
    "        List of geojson type objects, one per ensemble member. Each item as per deterministic but for the indicated ensemble member\n",
    "    bounds : list\n",
    "        Minimum and maximum longitude / latitude agregated across all ensemble members    \n",
    "    \"\"\"\n",
    "    # set map bounds, this will be updated as part of reading the data\n",
    "    bounds = [180,-180, 90, -90]\n",
    "    # open and create bufr handle\n",
    "    fh = open(filename,\"rb\")\n",
    "    bufr = codes_bufr_new_from_file(fh)\n",
    "    # unpack\n",
    "    codes_set(bufr,\"unpack\",True)\n",
    "    compressed = codes_get(bufr, 'compressedData')\n",
    "    # get storm identifier\n",
    "    stormIdentifier = codes_get(bufr, \"stormIdentifier\")\n",
    "    # get number of subsets\n",
    "    nSubsets = codes_get(bufr,\"numberOfSubsets\")\n",
    "    # get date and time of T0\n",
    "    year = codes_get(bufr,\"#1#year\")\n",
    "    month = codes_get(bufr,\"#1#month\")\n",
    "    day = codes_get(bufr,\"#1#day\")\n",
    "    hour = codes_get(bufr,\"#1#hour\")\n",
    "    minute = codes_get(bufr,\"#1#minute\")\n",
    "    t0 = dt(year=year, month=month, day=day, hour=hour, minute=minute)\n",
    "    # get location of low pressure centre at t0\n",
    "    lon0 = [float(val) for val in codes_get_array(bufr,\"#2#longitude\")]\n",
    "    if compressed and len(lon0) == 1 :\n",
    "        lon0 = lon0 * nSubsets\n",
    "    lat0 = [float(val) for val in codes_get_array(bufr,\"#2#latitude\")]\n",
    "    if compressed and len(lat0) == 1 :\n",
    "        lat0 = lat0 * nSubsets\n",
    "    # and the pressure\n",
    "    slp0 = [float(val) for val in codes_get_array(bufr,\"#1#pressureReducedToMeanSeaLevel\")]\n",
    "    if compressed and len(slp0) == 1:\n",
    "        slp0 = slp0*nSubsets\n",
    "    # get time periods\n",
    "    timePeriods = [float(val) for val in codes_get_array(bufr,\"timePeriod\")]\n",
    "    numberTimesteps = len(timePeriods)\n",
    "    \n",
    "    # now extract a track for each subset\n",
    "    objs = []\n",
    "    deterministic = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"MultiPoint\",\n",
    "            \"coordinates\": [ ]\n",
    "        },\n",
    "        \"properties\": {\n",
    "            \"stormIdentifier\": stormIdentifier,\n",
    "            \"datetime\": [ ],\n",
    "            \"slp\": [ ]\n",
    "        }        \n",
    "    }\n",
    "    subset = nSubsets - 1 # last ensemble member is deterministic\n",
    "    if lat0[subset] == CODES_MISSING_DOUBLE or lon0[subset] == CODES_MISSING_DOUBLE or slp0[subset] == CODES_MISSING_DOUBLE:\n",
    "            lat0[subset] = None\n",
    "            lon0[subset] = None\n",
    "            slp0[subset] = None\n",
    "    else:\n",
    "        deterministic['geometry']['coordinates'].append([lon0[subset], lat0[subset]])\n",
    "        deterministic['properties']['datetime'].append(t0)\n",
    "        deterministic['properties']['slp'].append(slp0[subset])\n",
    "        bounds[0] = min(bounds[0], lon0[subset])\n",
    "        bounds[1] = max(bounds[1], lon0[subset])\n",
    "        bounds[2] = min(bounds[2], lat0[subset])\n",
    "        bounds[3] = max(bounds[3], lat0[subset])\n",
    "    \n",
    "    for subset in range(nSubsets-2):\n",
    "        objs.append( {\n",
    "                \"type\": \"Feature\",\n",
    "                \"geometry\": {\n",
    "                    \"type\": \"MultiPoint\",\n",
    "                    \"coordinates\": []\n",
    "                },\n",
    "                \"properties\": {\n",
    "                    \"stormIdentifier\": stormIdentifier,\n",
    "                    \"ensembleMember\": subset,\n",
    "                    \"datetime\": [],\n",
    "                    \"slp\": []\n",
    "                }        \n",
    "            })    \n",
    "        if lat0[subset] == CODES_MISSING_DOUBLE or lon0[subset] == CODES_MISSING_DOUBLE or slp0[subset] == CODES_MISSING_DOUBLE:\n",
    "            lat0[subset] = None\n",
    "            lon0[subset] = None\n",
    "            slp0[subset] = None\n",
    "            continue\n",
    "        objs[subset]['geometry']['coordinates'].append([lon0[subset], lat0[subset]])\n",
    "        objs[subset]['properties']['datetime'].append(t0)\n",
    "        objs[subset]['properties']['slp'].append(slp0[subset])\n",
    "        bounds[0] = min(bounds[0], lon0[subset])\n",
    "        bounds[1] = max(bounds[1], lon0[subset])\n",
    "        bounds[2] = min(bounds[2], lat0[subset])\n",
    "        bounds[3] = max(bounds[3], lat0[subset])\n",
    "        \n",
    "    t = t0   \n",
    "    for idx in range(numberTimesteps):\n",
    "        indexNumber = (idx+1)*2 + 2    \n",
    "        lat = [float(val) for val in codes_get_array(bufr, f\"#{indexNumber:d}#latitude\")]\n",
    "        if compressed and len(lat) == 1:\n",
    "            lat = lat*nSubsets    \n",
    "        lon = [float(val) for val in codes_get_array(bufr, f\"#{indexNumber:d}#longitude\")]\n",
    "        if compressed and len(lon) == 1:\n",
    "            lon = lon*nSubsets        \n",
    "        slp = [float(val) for val in codes_get_array(bufr, f\"#{idx+2}#pressureReducedToMeanSeaLevel\")]\n",
    "        if compressed and len(slp) == 1:\n",
    "            slp = slp*nSubsets    \n",
    "        t = t0 + timedelta(hours=int(timePeriods[idx]))\n",
    "        for subset in range(nSubsets-2):\n",
    "            if lat[subset] == CODES_MISSING_DOUBLE or lon[subset] == CODES_MISSING_DOUBLE or slp[subset] == CODES_MISSING_DOUBLE:\n",
    "                lat[subset] = None\n",
    "                lon[subset] = None\n",
    "                slp[subset] = None\n",
    "            else:\n",
    "                objs[subset]['geometry']['coordinates'].append(  [lon[subset], lat[subset]]  )\n",
    "                objs[subset]['properties']['datetime'].append(t)\n",
    "                objs[subset]['properties']['slp'].append(slp[subset])\n",
    "                bounds[0] = min(bounds[0], lon[subset])\n",
    "                bounds[1] = max(bounds[1], lon[subset])\n",
    "                bounds[2] = min(bounds[2], lat[subset])\n",
    "                bounds[3] = max(bounds[3], lat[subset])\n",
    "    \n",
    "        subset = nSubsets - 1 # last ensemble member is deterministic\n",
    "        if lat[subset] == CODES_MISSING_DOUBLE or lon[subset] == CODES_MISSING_DOUBLE or slp[subset] == CODES_MISSING_DOUBLE:\n",
    "                lat[subset] = None\n",
    "                lon[subset] = None\n",
    "                slp[subset] = None\n",
    "        else:\n",
    "            deterministic['geometry']['coordinates'].append([lon[subset], lat[subset]])\n",
    "            deterministic['properties']['datetime'].append(t)\n",
    "            deterministic['properties']['slp'].append(slp[subset])\n",
    "            bounds[0] = min(bounds[0], lon[subset])\n",
    "            bounds[1] = max(bounds[1], lon[subset])\n",
    "            bounds[2] = min(bounds[2], lat[subset])\n",
    "            bounds[3] = max(bounds[3], lat[subset])\n",
    "\n",
    "    return stormIdentifier, t0, deterministic, objs, bounds\n",
    "\n",
    "\n",
    "def create_grid(bounds, resolution): \n",
    "    \"\"\"\n",
    "    Returns latitudes and longutudes for a regular grid with bounds and resolution based on \n",
    "    input parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bounds : list[float]\n",
    "        List of minimum and maximum longitudes and latitudes [lon min, lon max, lat min, lat max]\n",
    "    resolution: float\n",
    "        Resolution on which to create the grid\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    grid_longitudes : array[float, float]\n",
    "        Array of longitudes for grid box centres forming the grid.\n",
    "    grid_latitudes : array[float, float]\n",
    "        Array of latitudes for grid box centres forming the grid.\n",
    "    \n",
    "    \"\"\"\n",
    "    lons = np.arange(bounds[0], bounds[1] + resolution, resolution) \n",
    "    lats = np.arange(bounds[2], bounds[3] + resolution, resolution) \n",
    "    return np.meshgrid(lons, lats)\n",
    "\n",
    "\n",
    "def calculate_track_probabilities(tracks, grid_lons, grid_lats, distance_threshold):\n",
    "    \"\"\"\n",
    "    Demonstration showing a basic calculation of the probability that a tropical cyclone\n",
    "    track will pass within a set distance of each grid point.\n",
    "\n",
    "    NOTE: THIS CALCULAITON IS PROVIDED FOR DEMONSTRATION PURPOSES AND SHOULD NOT BE USED OPERATIONALLY\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tracks : list[list]\n",
    "        list of cyclone tracks from the ensemble. Each track is a list of MultiPoint objects giving the \n",
    "        position of the tropical cyclone centre at each timestep.\n",
    "    grid_lons : array[float, float]\n",
    "        List of longitudes for grid box centres forming the grid on which to perfrom the analysis.\n",
    "    grid_lats : array[float, float]\n",
    "        List of latitudes for grid box centres forming the grid on which to perfrom the analysis.\n",
    "    distance_threshold : numeric\n",
    "        Distance threshold (metres) to use in the calculation\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    probabilities : array[float,float]\n",
    "        2 dimensional array showing the probability of the tropical cyclone track passing within the\n",
    "        specified distance threshold.\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    # Create a geodetic distance calculator\n",
    "    geod = pyproj.Geod(ellps='WGS84')\n",
    "    # Create transformer objects\n",
    "    wgs84 = pyproj.CRS('EPSG:4326')\n",
    "    web_mercator = pyproj.CRS('EPSG:3857')\n",
    "    project = pyproj.Transformer.from_crs(wgs84, web_mercator, always_xy=True).transform\n",
    "    project_back = pyproj.Transformer.from_crs(web_mercator, wgs84, always_xy=True).transform\n",
    "    \n",
    "    # Function to create a buffer around a point\n",
    "    def point_buffer(lon, lat):\n",
    "        point = Point(lon, lat)\n",
    "        point_projected = transform(project, point)\n",
    "        buffer = point_projected.buffer(distance_threshold)\n",
    "        return transform(project_back, buffer)\n",
    "\n",
    "    probabilities = np.zeros_like(grid_lons)\n",
    "    total_tracks = len(tracks)\n",
    "\n",
    "    for i in range(grid_lons.shape[0]):\n",
    "        for j in range(grid_lons.shape[1]):\n",
    "            grid_point = Point(grid_lons[i, j], grid_lats[i, j])\n",
    "            buffer = point_buffer(grid_lons[i, j], grid_lats[i, j])            \n",
    "            tracks_within_buffer = sum(1 for track in tracks if buffer.intersects(track))\n",
    "            probabilities[i, j] = tracks_within_buffer / total_tracks\n",
    "\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe79280-2548-4ffd-89e6-4c7f886b6c31",
   "metadata": {},
   "source": [
    "### Loading the tropical cyclone track data and calculating the strike probabilities\n",
    "\n",
    "The following code bloack loads the data and performs the analysis of tropical cyclone strike probability.\n",
    "\n",
    "Note:\n",
    "- The analysis grid resolution (in degrees lat/lon) is specified by the `resolution` variable below. The finer the resolution the longer the processing time.\n",
    "- The distance threshold (in metres) is specified by the `distance_threshold` variable below. \n",
    "\n",
    "Note that the strike probability is calculated over all timesteps in the input BUFR file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d24b963-9c3e-4f2a-8af4-532a741e6c0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "stormIdentifier, t0, deterministic, ensemble, bounds = demo_load_cyclone_track(infile)\n",
    "# convert each trajectory into MultiPoint object\n",
    "tracks = [MultiPoint(feature['geometry']['coordinates']) for feature in ensemble]\n",
    "# use  1. degree grid for resolution, note that this is a very coarse grid for demonstration purposes, recommended is 0.1 degree (approx 10km)\n",
    "resolution = 1.\n",
    "# create grid\n",
    "grid_lons, grid_lats = create_grid(np.add(bounds, [-5, 5, -5, 5]), resolution)\n",
    "# set distance threshold (meters)\n",
    "distance_threshold = 200000\n",
    "# calculate probabilities\n",
    "probabilities = calculate_track_probabilities(tracks, grid_lons, grid_lats, distance_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f2a316-a24f-429e-bf88-207a9f660dee",
   "metadata": {},
   "source": [
    "### Displaying the results\n",
    "\n",
    "The next and final code block creates the figure showing the strike probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fc1e56-0622-4f09-981d-21e5ca3aa984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now a new map showing the strike probabilities\n",
    "fig, ax = plt.subplots(figsize=(18, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "# Set extent with 5 degree buffer\n",
    "ax.set_extent( np.add(bounds,[-5,5,-5,5]), crs=ccrs.PlateCarree() )\n",
    "\n",
    "# Add land, coastlines, etc.\n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.add_feature(cfeature.OCEAN)\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "\n",
    "# Overlay probabilities\n",
    "cs = ax.contourf(grid_lons, grid_lats, probabilities, levels=10, cmap='YlOrRd', transform=ccrs.PlateCarree(), alpha=0.7)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(cs, ax=ax, orientation='vertical', pad=0.1)\n",
    "cbar.set_label('Probability')\n",
    "\n",
    "# Add title and labels\n",
    "t = deterministic['properties']['datetime'][-1]\n",
    "\n",
    "plt.title(f'Probability of tropical storm track within {int(distance_threshold/1000)}km\\n{t0} - {t}', fontsize=16)\n",
    "plt.text(bounds[0]-4.5, bounds[3]+3, f\"Storm: {stormIdentifier}\")\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "\n",
    "# Add gridlines\n",
    "ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False)\n",
    "\n",
    "# Add deterministic track and pressures at midnight\n",
    "lon, lat = zip( *deterministic['geometry']['coordinates'])\n",
    "\n",
    "ax.plot(lon, lat, marker=\"o\", transform=ccrs.PlateCarree())\n",
    "for idx in range(len(lon)):\n",
    "    if deterministic['properties']['datetime'][idx].hour == 0:\n",
    "        plt.text(lon[idx], lat[idx]+1,deterministic['properties']['datetime'][idx].date(), horizontalalignment='center', transform=ccrs.PlateCarree() )\n",
    "        plt.text(lon[idx], lat[idx]-1,deterministic['properties']['slp'][idx]/100.0, horizontalalignment='center', verticalalignment='bottom',transform=ccrs.PlateCarree() )\n",
    "\n",
    "# now show\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
